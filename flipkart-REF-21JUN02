import sys

# install chromium, its driver, and selenium
if 'google.colab' in sys.modules:
    !apt-get update
    !apt install chromium-chromedriver
    !cp /usr/lib/chromium-browser/chromedriver/usr/bin
    !pip install selenium

print("!! PACKAGE DOWNLOAD COMPLETE !!")

from google.colab import drive
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver import ActionChains
from bs4 import BeautifulSoup
import pandas as pd
import requests
import os
import time
from openpyxl import load_workbook


options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument("window-size=1920x1080")
# open it, go to a website, and get results
driver = webdriver.Chrome('chromedriver',options=options)

print('!! BASIC SETTING COMPLETE !!')


Price_infos = []

driver.get(f'https://www.flipkart.com/search?sid=j9e%2Fabm%2Fhzg&otracker=CLP_Filters&p%5B%5D=facets.brand%255B%255D%3DLG&p%5B%5D=facets.brand%255B%255D%3DWhirlpool&p%5B%5D=facets.brand%255B%255D%3DHaier&p%5B%5D=facets.brand%255B%255D%3DGodrej&p%5B%5D=facets.brand%255B%255D%3DSAMSUNG&p%5B%5D=facets.brand%255B%255D%3DPanasonic')

last_number = int(driver.find_element_by_xpath('//*[@id="container"]/div/div[3]/div/div[2]/div[26]/div/div/span[1]').text[10:])


for i in range(1,last_number+1):   

    time.sleep(0.3)
    print('Current page is : ' + str(i) )    
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);") #Scroll to the end of the page
    time.sleep(1)  #sleep_between_interactions

    for j in range(2,25):
        try:
            name = driver.find_element_by_xpath('//*[@id="container"]/div/div[3]/div/div[2]/div['+str(j)+']/div/div/div/a/div[2]/div[1]/div[1]').text

        except:
        #이름이 없다는 건 마지막 페이지이고(마지막페이지만 24개 이하 상품이 존재), Break를 써서 종료시켜줌
            break

        mrp = driver.find_element_by_xpath('//*[@id="container"]/div/div[3]/div/div[2]/div['+str(j)+']/div/div/div/a/div[2]/div[2]/div[1]/div/div[2]').text[1:]
        price = driver.find_element_by_xpath('//*[@id="container"]/div/div[3]/div/div[2]/div['+str(j)+']/div/div/div/a/div[2]/div[2]/div[1]/div/div[1]').text[1:]
        link = driver.find_element_by_xpath('//*[@id="container"]/div/div[3]/div/div[2]/div['+str(j)+']/div/div/div/a').get_attribute('href')

        Price_info = [name, mrp, price, link]
        Price_infos.append(Price_info)

print('!! PRICE INFO COMPLETE !!')

data = pd.DataFrame(Price_infos)
data.columns = ['Name', 'MRP', 'Price', "URL"]

data.to_excel('/content/Price_Info_Flipkart_REF_2021JUN02.xlsx') #날짜update

print('!! FIND FILE !!')
